{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4923ec2c",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "Starting point for a supervised learning model for Ookla speed tiles. The data comes from a combination of \n",
    "Ookla Open Data speed tests and Statistics Canada information, including 2016 census population data and census boundaries (shapefiles). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e11b16f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e59298bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import src.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0120861",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from src.datasets.loading import statcan, ookla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44a651b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import geopandas as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7747ae1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing, pipeline, compose\n",
    "from sklearn import linear_model, model_selection, svm\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28af861b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary config/cache directory at /tmp/matplotlib-4yww8lr4 because the default path (/home/jovyan/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14697af4",
   "metadata": {},
   "source": [
    "## Load \n",
    "Load some of the available data. The census population data and StatCan boundaries are automatically loaded from \n",
    "the StatCan website. The overlays and tile geometries/speeds need to pre-computed and saved to the overlays directory and data directories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dee2f19",
   "metadata": {},
   "source": [
    "### Load All Unique Tile Gemoetries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f33da9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ookla_tiles = ookla.canada_tiles()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99eb5de",
   "metadata": {},
   "source": [
    "### Load Census Population Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b6832deb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/src/datasets/loading/statcan.py:234: DtypeWarning: Columns (3,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  return pd.read_csv(POP_FILE)\n"
     ]
    }
   ],
   "source": [
    "da_pops = statcan.dissemination_areas_populations()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f62db26",
   "metadata": {},
   "source": [
    "### Labelling Tiles\n",
    "Generate labels from geometric overlay of the Ookla tiles and Statistics Canada Dissemination Areas (DA). \n",
    "Label each tile with the information from the StatCan areas based on which DA the tile overlaps the most with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d2a7bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "o = gp.read_file(src.config.OVERLAYS_DIR / 'tile_das_overlay') #this can take a few minutes to load.\n",
    "tile_da_label = o.dropna(subset=['DAUID','quadkey']).sort_values(by=['quadkey','tile_frac'],ascending=False).drop_duplicates(subset='quadkey', keep='first')\n",
    "tile_da_label['quadkey'] = tile_da_label['quadkey'].astype(int)\n",
    "tile_da_label['DAUID'] = tile_da_label['DAUID'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0112f24",
   "metadata": {},
   "source": [
    "### Speed Test Data\n",
    "Load in the previous 4 quarters of data. Since we're currently in Q3 of 2022, the most recent quarter is Q2 \n",
    "so we can slice the files listed to grab those. Subsequently, we'll calculate weighted averages for individual tiles and use those as representative speeds for our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "246ca578",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_4_quarters = ookla.speed_data(ookla.available_files().loc[('fixed',2021,3):('fixed',2022,2)].path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8149cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "down = last_4_quarters.groupby('quadkey').apply(lambda s:np.average(s.avg_d_kbps, weights=s.tests)).rename('avg_d_kbps')\n",
    "up = last_4_quarters.groupby('quadkey').apply(lambda s:np.average(s.avg_u_kbps, weights=s.tests)).rename('avg_u_kbps')\n",
    "tests = last_4_quarters.groupby('quadkey')['tests'].sum()\n",
    "devices = last_4_quarters.groupby('quadkey')['devices'].sum()\n",
    "last4_agg = pd.concat([down, up, tests, devices],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd02857a",
   "metadata": {},
   "source": [
    "### Merge All The Data\n",
    "It's a bit messy, but we're merging several tables and removing a few of the redundant or non-useful \n",
    "columns as we go through. At the end the `features_table` variable will have all of the \n",
    "tiles within census areas labelled by what type of Census Subdivision, Dissemination Area, Population Centre, etc. they are in, as well as population information for the DA (smallest area with populations available) and the speed test averages over the last 4 quarters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a3bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge dissemination area (DA) populations with ookla tiles (already combined with other statcan data)\n",
    "features_table = tile_da_label.merge(da_pops, on='DAUID', how='left')\n",
    "features_table['DAPOP'] = features_table['DAPOP'].fillna(0).astype(int)\n",
    "del features_table['GEO_NAME']\n",
    "features_table = pd.DataFrame(features_table)\n",
    "del features_table['geometry']\n",
    "features_table['POP_DENSITY'] = features_table['DAPOP']/features_table['das_area']*1000**2 #people per square kilometer\n",
    "\n",
    "# take all ookla tiles, merge the speeds data and tile labels and populations\n",
    "features_table = ookla_tiles.merge(last4_agg, on='quadkey').merge(features_table, on='quadkey')\n",
    "\n",
    "# compute spatial joins to identify if area is a population centre\n",
    "pop_info = statcan.boundary('population_centres').to_crs('epsg:4326')\n",
    "pop_info = pop_info[['PCUID', 'PCNAME', 'PCTYPE', 'PCPUID', 'PCCLASS', 'geometry']] ##removes some redundant cols from DAs\n",
    "features_table = features_table.sjoin(pop_info, how='left')\n",
    "del features_table['index_right']\n",
    "features_table = features_table.sort_values(by=['PCUID','quadkey']).drop_duplicates(subset=['quadkey']) #keep tiles where overlap was true"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6d808",
   "metadata": {},
   "source": [
    "### Categorize All the Columns\n",
    "All the columns from our joins above can be roughly split into categories based on the type of \n",
    "data and how you might use them in a simple supervised learning problem. These are broken down as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9a4ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pkey = 'quadkey'\n",
    "geometry = 'geometry'\n",
    "id_and_names = ['DAUID', 'CDUID', 'CDNAME', 'CCSUID', 'CSDNAME', 'CMAUID', 'CMAPUID', 'CMANAME', \n",
    "'CCSNAME', 'CSDUID', 'ERUID', 'ERNAME', 'CTUID', 'CTNAME', 'ADAUID', \n",
    "'PCUID', 'PCNAME', 'PCPUID', 'SACCODE',] ##SACCODE is half a category half ID values\n",
    "\n",
    "categorical_labels = [\n",
    "    #'PRUID', #PRUID is redundant with PRNAME\n",
    "    'PRNAME', 'CDTYPE', \n",
    "    'CSDTYPE',  \n",
    "    'SACTYPE', \n",
    "    'CMATYPE', 'PCTYPE', 'PCCLASS',\n",
    "]\n",
    "numerical_vars = [\n",
    "    'tests', 'devices',\n",
    "    'das_area', 'tile_area', 'tile_frac',  'das_frac', \n",
    "    'DAPOP','POP_DENSITY'\n",
    "]\n",
    "target_vars = ['avg_d_kbps', 'avg_u_kbps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97dbe082",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_subset = [pkey] + categorical_labels + numerical_vars + target_vars\n",
    "features_table.loc[:,col_subset].set_index('quadkey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cafdffc-f2ee-43b5-9b9c-a670ad6f5f38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "features_table.info()#features_table.to_csv(\"Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ffacfe-0a63-46bf-98b3-7937dcc8a047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#As we want to wokr with the MBps speed adding a column with MBPS of up and down streams.\n",
    "features_table[\"avg_d_mbps\"]=features_table[\"avg_d_kbps\"]//1000.0\n",
    "features_table[\"avg_u_mbps\"]=features_table[\"avg_u_kbps\"]//1000.0\n",
    "features_table.describe()\n",
    "#features_table.to_csv(\"Features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e82510-6544-4e32-aefb-d993fb2fa3b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Finding unique values for each columns\n",
    "for i in range(0,38):\n",
    "    print(\"-------Finding unique values in column ----------- \"+ features_table.columns[i])\n",
    "    print(features_table[features_table.columns[i]].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0cbdb4-f442-47bb-b522-56f7a4742faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from pandas import DataFrame\n",
    "import seaborn as sns\n",
    "#features_table_realtion = features_table.drop(columns=[\"quadkey\",\"geometry\"])\n",
    "features_table_realtion = features_table.filter(['avg_d_mbps','avg_u_mbps','tests','devices','POP_DENSITY'], axis=1).head(1000)\n",
    "sns.heatmap(features_table_realtion, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23458920-b237-489a-9618-3ecd2a43dc82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Mean and Standard dev for each provience along with total size of location in each provience0) \n",
    "Feature_all_downspeed = features_table.groupby(\"PRNAME\")[\"avg_d_mbps\"].agg(['size','mean','std']).reset_index()\n",
    "Feature_all_downspeed.columns = [\"Proviences\",\"Size_Total\",\"Mean_Download_Speed\",\"std_Download_Speed\"]\n",
    "Feature_all_downspeed.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c75ce3-cb31-44c7-9baa-b3dbf3ad9942",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Feature_all_upspeed = features_table.groupby(\"PRNAME\")[\"avg_u_mbps\"].agg(['size','mean','std']).reset_index()\n",
    "Feature_all_upspeed.columns = [\"Proviences\",\"Size_Total\",\"Mean_Upload_Speed\",\"STD_Upload_Speed\"]\n",
    "Feature_all_upspeed.head(13)\n",
    "\n",
    "#TODO: Size total will be used to find the gap between total location having internet vs Total location not meeting the speed criteria the GAP.\n",
    "\n",
    "frames=[Feature_all_downspeed,Feature_all_upspeed]\n",
    "result = pd.concat(frames,axis=1)\n",
    "result = result.T.drop_duplicates().T\n",
    "result.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f95db3f-ba1a-480b-b00d-88d938a648e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Similarly repeating process for internet criteria\n",
    "#Finding how many locations does not meet the criteria of min up/download speed by provience\n",
    "Query_up_down_speed = features_table.query('avg_d_mbps < 50 | avg_u_mbps < 10')\n",
    "\n",
    "#For Download speeed\n",
    "Query_downspeed = Query_up_down_speed.groupby(\"PRNAME\")[\"avg_d_mbps\"].agg(['size','mean','std',]).reset_index()\n",
    "Query_downspeed.columns = [\"Proviences\",\"Crt_Size_Total\",\"Crt_Mean_Download_Speed\",\"Crt_std_Download_Speed\"]\n",
    "Query_downspeed.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7f552a-a1ea-4f4c-bd10-48ba43f13390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For upload speed\n",
    "Query_upspeed = Query_up_down_speed.groupby(\"PRNAME\")[\"avg_u_mbps\"].agg(['size','mean','std']).reset_index()\n",
    "Query_upspeed.columns = [\"Proviences\",\"Crt_Size_Total\",\"Crt_Mean_Up_Speed\",\"Crt_std_Up_Speed\"]\n",
    "Query_upspeed.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1af5a8-4c7c-4bf7-9bc4-926def163726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "frames_crt=[Query_downspeed,Query_upspeed]\n",
    "result_crt = pd.concat(frames_crt,axis=1)\n",
    "result_crt = result_crt.T.drop_duplicates().T\n",
    "result_crt.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44235fe-9ca7-4d6f-935c-fb1aa07cf831",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Merging boeth the result tables having all the mean,std,size details for actual and expected criteria\n",
    "frames_final=[result,result_crt]\n",
    "result_find_gap = pd.concat(frames_final,axis=1)\n",
    "result_find_gap = result_find_gap.T.drop_duplicates().T\n",
    "result_find_gap.head(13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709898a3-a4f1-4f55-b4e8-ba60edc72092",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Adding percentage column to find the gap and better understanding\n",
    "result_find_gap[\"Percentage_gap\"] = (result_find_gap[\"Crt_Size_Total\"]/result_find_gap[\"Size_Total\"])*100\n",
    "result_find_gap.to_csv(\"Gap Analysis.csv\")\n",
    "result_find_gap.sort_values(by=\"Percentage_gap\", ascending=False,inplace=True)\n",
    "result_find_gap.head(13)\n",
    "\n",
    "import plotly.express as px\n",
    "fig = px.bar(result_find_gap, x='Proviences',y='Percentage_gap')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab732a8b-74d9-499c-97c5-4a00a9da71af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Proviences</th>\n",
       "      <th>Size_Total</th>\n",
       "      <th>Mean_Download_Speed</th>\n",
       "      <th>std_Download_Speed</th>\n",
       "      <th>Mean_Upload_Speed</th>\n",
       "      <th>STD_Upload_Speed</th>\n",
       "      <th>Crt_Size_Total</th>\n",
       "      <th>Crt_Mean_Download_Speed</th>\n",
       "      <th>Crt_std_Download_Speed</th>\n",
       "      <th>Crt_Mean_Up_Speed</th>\n",
       "      <th>Crt_std_Up_Speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Alberta</td>\n",
       "      <td>46933</td>\n",
       "      <td>88.960220</td>\n",
       "      <td>99.179564</td>\n",
       "      <td>33.174589</td>\n",
       "      <td>51.976972</td>\n",
       "      <td>28645</td>\n",
       "      <td>27.335870</td>\n",
       "      <td>29.772997</td>\n",
       "      <td>6.957689</td>\n",
       "      <td>8.556512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>British Columbia / Colombie-Britannique</td>\n",
       "      <td>37060</td>\n",
       "      <td>150.566838</td>\n",
       "      <td>124.436208</td>\n",
       "      <td>64.355235</td>\n",
       "      <td>72.662968</td>\n",
       "      <td>11520</td>\n",
       "      <td>30.925174</td>\n",
       "      <td>34.779705</td>\n",
       "      <td>9.908247</td>\n",
       "      <td>12.759966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Manitoba</td>\n",
       "      <td>20194</td>\n",
       "      <td>81.436318</td>\n",
       "      <td>86.908821</td>\n",
       "      <td>31.959493</td>\n",
       "      <td>59.413703</td>\n",
       "      <td>12260</td>\n",
       "      <td>30.634502</td>\n",
       "      <td>33.202787</td>\n",
       "      <td>6.107259</td>\n",
       "      <td>11.330834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>New Brunswick / Nouveau-Brunswick</td>\n",
       "      <td>13229</td>\n",
       "      <td>141.915715</td>\n",
       "      <td>138.299939</td>\n",
       "      <td>39.408723</td>\n",
       "      <td>58.845470</td>\n",
       "      <td>5370</td>\n",
       "      <td>28.741527</td>\n",
       "      <td>38.468404</td>\n",
       "      <td>5.584171</td>\n",
       "      <td>11.586166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Newfoundland and Labrador / Terre-Neuve-et-Lab...</td>\n",
       "      <td>6747</td>\n",
       "      <td>141.556544</td>\n",
       "      <td>120.608244</td>\n",
       "      <td>43.766859</td>\n",
       "      <td>63.201958</td>\n",
       "      <td>2912</td>\n",
       "      <td>56.487294</td>\n",
       "      <td>81.856997</td>\n",
       "      <td>5.619849</td>\n",
       "      <td>8.362949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                         Proviences  Size_Total   \n",
       "0           0                                            Alberta       46933  \\\n",
       "1           1            British Columbia / Colombie-Britannique       37060   \n",
       "2           2                                           Manitoba       20194   \n",
       "3           3                  New Brunswick / Nouveau-Brunswick       13229   \n",
       "4           4  Newfoundland and Labrador / Terre-Neuve-et-Lab...        6747   \n",
       "\n",
       "   Mean_Download_Speed  std_Download_Speed  Mean_Upload_Speed   \n",
       "0            88.960220           99.179564          33.174589  \\\n",
       "1           150.566838          124.436208          64.355235   \n",
       "2            81.436318           86.908821          31.959493   \n",
       "3           141.915715          138.299939          39.408723   \n",
       "4           141.556544          120.608244          43.766859   \n",
       "\n",
       "   STD_Upload_Speed  Crt_Size_Total  Crt_Mean_Download_Speed   \n",
       "0         51.976972           28645                27.335870  \\\n",
       "1         72.662968           11520                30.925174   \n",
       "2         59.413703           12260                30.634502   \n",
       "3         58.845470            5370                28.741527   \n",
       "4         63.201958            2912                56.487294   \n",
       "\n",
       "   Crt_std_Download_Speed  Crt_Mean_Up_Speed  Crt_std_Up_Speed  \n",
       "0               29.772997           6.957689          8.556512  \n",
       "1               34.779705           9.908247         12.759966  \n",
       "2               33.202787           6.107259         11.330834  \n",
       "3               38.468404           5.584171         11.586166  \n",
       "4               81.856997           5.619849          8.362949  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_visualization_gap = pd.read_csv(\"./data/Gap_Analysis.csv\")\n",
    "for_visualization_gap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d38d816-1253-4d69-b166-14ce97682bff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "7baa5682b3ee41d95f3e6c53f6f101854543f295d881c00164f5d254f1692751"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
